{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded : Done\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('labeled_10k.csv') \n",
    "print(\"Dataset Loaded : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing 1 : Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = dataset\n",
    "dummies = pd.get_dummies(df.country)\n",
    "merged = pd.concat([df,dummies], axis='columns')\n",
    "\n",
    "print(\"Data Processing 1 : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing 2 : Done\n"
     ]
    }
   ],
   "source": [
    "final = merged.drop(['country', 'SWE'],axis='columns')\n",
    "\n",
    "Y_agency = final.agency\n",
    "Y_social = final.social\n",
    "\n",
    "\n",
    "X = final.drop('agency',axis='columns')\n",
    "X = X.drop('social',axis='columns')\n",
    "\n",
    "dummies = pd.get_dummies(X.concepts)\n",
    "X = pd.concat([X,dummies], axis='columns')\n",
    "\n",
    "X = X.drop(['gender', 'hmid', 'concepts', 'animals', 'married', 'parenthood', 'reflection', 'duration'],axis='columns')\n",
    "\n",
    "print(\"Data Processing 2 : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing 3 : Done\n"
     ]
    }
   ],
   "source": [
    "#X[\"age\"] = apply(pd.to_numeric(X[\"age\"]))\n",
    "\n",
    "X[[\"age\"]] = X[[\"age\"]].apply(pd.to_numeric,  errors='coerce')\n",
    "\n",
    "print(\"Data Processing 3 : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing 4 : Done\n"
     ]
    }
   ],
   "source": [
    "tmp = X\n",
    "tmp = tmp.drop(['moment'],axis='columns')\n",
    "\n",
    "print(\"Data Processing 4 : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare Anagram List : Done\n"
     ]
    }
   ],
   "source": [
    "#df1 = dataset[['moment']]\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict \n",
    "\n",
    "moment_List = dataset['moment'].values\n",
    "data = []\n",
    "data_process = []\n",
    "count_data = defaultdict(int)\n",
    "\n",
    "for count,value in enumerate(moment_List):\n",
    "    Four_grams = ngrams(value.split(), 4)\n",
    "    token_freq = nltk.FreqDist(Four_grams)\n",
    "    for token in token_freq.keys():\n",
    "        str1=\"\"\n",
    "        for val in token:\n",
    "            str1 += val+\" \"\n",
    "        data_process.append(str1)\n",
    "        data.append((count,str1))\n",
    "        count_data[count] += 1\n",
    "\n",
    "print(\"Prepare Anagram List : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency Value set : Done\n",
      "Social Value set : Done\n"
     ]
    }
   ],
   "source": [
    "agency      = dataset['agency'].values\n",
    "social      = dataset['social'].values\n",
    "\n",
    "for n, i in enumerate(agency):\n",
    "    if i == 'no':\n",
    "        agency[n]=0\n",
    "    else:\n",
    "        agency[n]=1\n",
    "        \n",
    "for n, i in enumerate(social):\n",
    "    if i == 'no':\n",
    "        social[n]=0\n",
    "    else:\n",
    "        social[n]=1\n",
    "        \n",
    "print(\"Agency Value set : Done\")\n",
    "print(\"Social Value set : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_Agency Prepared : Done\n",
      "Y_Social Prepared : Done\n"
     ]
    }
   ],
   "source": [
    "column_values = pd.Series(data_process)\n",
    "df = pd.DataFrame(data) \n",
    "\n",
    "y_agency=[]\n",
    "for i,j in zip(count_data.values(), agency):\n",
    "    for val in range(0,i):\n",
    "        y_agency.append(j)\n",
    "        \n",
    "y_social=[]\n",
    "for i,j in zip(count_data.values(), social):\n",
    "    for val in range(0,i):\n",
    "        y_social.append(j)\n",
    "\n",
    "print(\"Y_Agency Prepared : Done\")\n",
    "print(\"Y_Social Prepared : Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def split_list(a_list, y):\n",
    "    return a_list[:y], a_list[y+1:]\n",
    "\n",
    "\n",
    "x = int(0.2*len(y_agency))+1\n",
    "y = int(len(y_agency) - 0.2*len(y_agency))\n",
    "y_agency_train, y_agency_test = split_list(y_agency,y)\n",
    "\n",
    "x_train_, x_test_ = split_list(data_process, y)\n",
    "\n",
    "y_social_train, y_social_test = split_list(y_social, y)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer : Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "x_train = tf_idf.fit_transform(x_train_)\n",
    "x_test = tf_idf.transform(x_test_)\n",
    "\n",
    "x_train.toarray()\n",
    "\n",
    "print(\"Vectorizer : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Agency :  72.54830808309897 % accuracy\n",
      "Naive Bayes Model Fit : Done\n"
     ]
    }
   ],
   "source": [
    "# Predicting Agency\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "# y_agency=y_agency.astype('int')\n",
    "mnb.fit(x_train.toarray(), y_agency_train)\n",
    "\n",
    "y_pred = mnb.predict(x_test)\n",
    "\n",
    "count=0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_agency_test[i]:\n",
    "        count += 1\n",
    "\n",
    "print(\"Naive Bayes Agency : \",count/len(y_pred) * 100,\"% accuracy\")\n",
    "\n",
    "print(\"Naive Bayes Model Fit : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes :  50.19051075024947 % accuracy\n",
      "Naive Bayes Model Fit : Done\n"
     ]
    }
   ],
   "source": [
    "# Predicting Social\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "# y_agency=y_agency.astype('int')\n",
    "mnb.fit(x_train.toarray(), y_social_train)\n",
    "\n",
    "y_pred = mnb.predict(x_test)\n",
    "\n",
    "count=0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_social_test[i]:\n",
    "        count += 1\n",
    "\n",
    "print(\"Naive Bayes : \",count/len(y_pred) * 100,\"% accuracy\")\n",
    "\n",
    "print(\"Naive Bayes Model Fit : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
